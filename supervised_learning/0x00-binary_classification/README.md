# 0x00. Binary Classification

## Specializations - Machine Learning ― Supervised Learning

![Classification](https://imgur.com/42vqH03)

## Tasks

You have n number of locked boxes in front of you. Each box is numbered sequentially from 0 to n - 1 and each box may contain keys to the other boxes. Write a method that determines if all the boxes can be opened.

  * Prototype: def canUnlockAll(boxes)
  * boxes is a list of lists
  * A key with the same number as a box opens that box
  * You can assume all keys will be positive integers
  * The first box boxes[0] is unlocked
  * Return True if all boxes can be opened, else return False


## Background Context
Welcome to your first project on supervised learning! At the end of this project, you should be able to build your own binary image classifier from scratch using numpy. As you might already see, there are a LOT of resources for you to read/watch. It may be tempting to dive into the projects right away, but it is HIGHLY RECOMMENDED that you spend AT LEAST 1 whole day going over the following materials. You should only start the project once you have a decent understanding of all the topics mentioned in Learning Objectives. You may also notice that there are multiple resources that cover the same topic, with some more technical than others. If you find yourself getting lost in a resource, move on to another and come back to the more technical one after you intuitively understand that topic. Good luck and have fun!

## Resources
### Read or watch:

  *  Predictive analytics
  *  Maximum Likelihood Estimation
  *  How would you explain neural networks to someone who knows very little about AI or neurology?
  *  Supervised vs. Unsupervised Machine Learning
  *  Using Neural Nets to Recognize Handwritten Digits (until “A simple network to classify handwritten digits” (excluded))
  *  Forward propagation
  *  Understanding Activation Functions in Neural Networks
  *  Loss function
  *  Gradient descent
  *  Calculus on Computational Graphs: Backpropagation
  *  Backpropagation calculus
  *  What is a Neural Network?
  *  Supervised Learning with a Neural Network
  *  Binary Classification
  *  Logistic Regression
  *  Logistic Regression Cost Function
  *  Gradient Descent
  *  Computation Graph
  *  Logistic Regression Gradient Descent
  *  Vectorization
  *  Vectorizing Logistic Regression
  *  Vectorizing Logistic Regression’s Gradient Computation
  *  A Note on Python/Numpy Vectors
  *  Neural Network Representations
  *  Computing Neural Network Output
  *  Vectorizing Across Multiple Examples
  *  Gradient Descent For Neural Networks
  *  Random Initialization
  *  Deep L-Layer Neural Network
  *  Train/Dev/Test Sets
  *  Random Initialization For Neural Networks : A Thing Of The Past
  *  Initialization of deep networks
  *  numpy.zeros
  *  numpy.random.randn
  *  numpy.exp
  *  numpy.log
  *  numpy.sqrt
  *  numpy.where



## Learning Objectives
At the end of this project, you are expected to be able to explain to anyone, without the help of Google:

  *  General
  *  What is a model?
  *  What is supervised learning?
  *  What is a prediction?
  *  What is a node?
  *  What is a weight?
  *  What is a bias?
  *  What are activation functions?
  *  - Sigmoid?
  *  - Tanh?
  *  - Relu?
  *  - Softmax?
  *  What is a layer?
  *  What is a hidden layer?
  *  What is Logistic Regression?
  *  What is a loss function?
  *  What is a cost function?
  *  What is forward propagation?
  *  What is Gradient Descent?
  *  What is back propagation?
  *  What is a Computation Graph?
  *  How to initialize weights/biases
  *  The importance of vectorization
  *  How to split up your data
